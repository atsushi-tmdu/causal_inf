{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from numpy.random import *\n",
    "import matplotlib.pyplot as plt \n",
    "#np.random.seed(100)\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "\n",
    "import csv\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 1234\n",
    "rng = np.random.RandomState(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device='cuda'\n",
    "else:\n",
    "    device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.random.binomial(1,0.5,size=70000)\n",
    "x2 = np.random.normal(x1*0.4+0.5,0.2)\n",
    "effect = 1.5\n",
    "beta2 = 0.8\n",
    "eps = 1e-10\n",
    "b = np.random.normal(0,0.2)\n",
    "\n",
    "\n",
    "def kaiki(x1=x1,x2=x2,effect=effect,beta2=beta2,b=b):\n",
    "    return effect*x1+beta2*x2+b\n",
    "\n",
    "yogo = kaiki(x1,x2)\n",
    "data = np.array((x1,x2,yogo)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 987,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:60000].shape\n",
    "train = data[:60000]#train[0]:conditional, train[1]:feature, train[2]:outcome\n",
    "test  = data[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 988,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_iters = 24000\n",
    "num_epochs = int(batch_size* num_iters/len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train, batch_size = batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 990,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pixyz.distributions import Bernoulli, Normal\n",
    "from pixyz.losses import KullbackLeibler\n",
    "from pixyz.models import VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 992,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inference(Normal):\n",
    "    def __init__(self, input_dim,cond_dim, hidden_dim, latent_dim):\n",
    "        super(Inference, self).__init__(cond_var=[\"x\",\"y\"], var=[\"z\"], name=\"q\")\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim+cond_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc31 = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc32 = nn.Linear(hidden_dim, latent_dim)\n",
    "    def forward(self,x,y):\n",
    "        h = F.relu(self.fc1(torch.cat([x,y],1)))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        return {\"loc\": self.fc31(h), \"scale\": F.softplus(self.fc32(h))}\n",
    "\n",
    "class Generator(Bernoulli):\n",
    "    def __init__(self, latent_dim,cond_dim, hidden_dim, output_dim):\n",
    "        super(Generator, self).__init__(cond_var=[\"z\",\"y\"], var=[\"x\"], name=\"p\")\n",
    "        \n",
    "        self.fc1 = nn.Linear(latent_dim+cond_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self,z,y):\n",
    "        h = F.relu(self.fc1(torch.cat([z,y],1)))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        return{\"probs\": F.sigmoid(self.fc3(h))}\n",
    "\n",
    "class Estimator(Normal):\n",
    "    def __init__(self, cond_dim, hidden_dim, latent_dim, estimate_dim):\n",
    "        super(Estimator, self).__init__(cond_var=[\"z\",\"y\"], var=[\"e\"], name=\"e\")\n",
    "        \n",
    "        self.fc1 = nn.Linear(latent_dim+cond_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, estimate_dim)\n",
    "        \n",
    "    def forward(self,z,y):\n",
    "        h = F.relu(self.fc1(torch.cat([z,y],1)))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        return{\"value\": self.fc3(h)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 1\n",
    "hidden_dim = 200\n",
    "latent_dim = 10\n",
    "output_dim = 1\n",
    "cond_dim = 2\n",
    "estimate_dim =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Estimator(\n",
       "  (fc1): Linear(in_features=12, out_features=200, bias=True)\n",
       "  (fc2): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (fc3): Linear(in_features=200, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 994,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Generator(latent_dim,cond_dim, hidden_dim, output_dim)\n",
    "q = Inference(input_dim,cond_dim, hidden_dim, latent_dim)\n",
    "e = Estimator(cond_dim, hidden_dim, latent_dim, estimate_dim)\n",
    "\n",
    "p.to(device)\n",
    "q.to(device)\n",
    "e.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = torch.tensor(0.)\n",
    "scale = torch.tensor(1.)\n",
    "prior = Normal(loc=loc, scale=scale, var=[\"z\"], dim= latent_dim, name=\"p_prior\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 996,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl = KullbackLeibler(q,prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(q,p, regularizer = kl, optimizer=optim.Adam, optimizer_params={\"lr\":1e-3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_shaper(x,y, input_dim):\n",
    "    x = x.view(-1, input_dim).float()\n",
    "    y = torch.eye(2)[y.long()].float()\n",
    "    return x,y\n",
    "\n",
    "def train(epoch, input_dim):\n",
    "    train_loss = 0\n",
    "    for data in tqdm(train_loader):\n",
    "        y = data[:,0]\n",
    "        x = data[:,1]\n",
    "        x, y = data_shaper(x, y, input_dim)\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "       \n",
    "        loss = model.train({\"x\":x, \"y\":y})\n",
    "        train_loss += loss\n",
    "    #pytorchのlossはデフォルトでは平均の値になる。このためバッチ長をかけて\n",
    "    #全体で割って全体のlossを計算する\n",
    "    \n",
    "    train_loss = train_loss * train_loader.batch_size / len(train_loader.dataset)\n",
    "    print('Epoch:{} Train loss:{:.4f}'.format(epoch, train_loss))\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, input_dim):\n",
    "    test_loss = 0\n",
    "    for data in test_loader:\n",
    "        y = data[:,0]\n",
    "        x = data[:,1]\n",
    "        x, y = data_shaper(x,y, input_dim)\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        loss = model.test({\"x\":x, \"y\":y})\n",
    "        test_loss += loss\n",
    "    test_loss = test_loss * test_loader.batch_size/ len(test_loader.dataset)\n",
    "    print('Test loss:{:.4f}'.format(test_loss))\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reconstrunction(x,y,output_dim):\n",
    "    with torch.no_grad():\n",
    "        z = q.sample({\"x\":x, \"y\":y}, return_all=False)\n",
    "        z.update({\"y\":y})\n",
    "        recon_batch = p.sample_mean(z).view(-1, output_dim)\n",
    "        recon = torch.cat([x.view(-1, output_dim), recon_batch]).cpu()\n",
    "        return recon\n",
    "\n",
    "def plot_image_from_latent(z,y, output_dim):\n",
    "    with torch.no_grad():\n",
    "        sample = p.sample_mean({\"z\":z, \"y\":y}).view(-1, output_dim).cpu()\n",
    "        return sample\n",
    "\n",
    "def plot_reconstraction_changing_y(x,y, output_dim):\n",
    "    y_change = torch.eye(2)[range(2)].to(device)\n",
    "    batch_dummy = torch.ones(x.size(0))[:, None].to(device)\n",
    "    recon_all = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _y in y_change:\n",
    "            z = q.sample({\"x\": x, \"y\": y}, return_all=False)\n",
    "            z.update({\"y\": batch_dummy * _y[None,:]})\n",
    "            recon_batch = p.sample_mean(z).view(-1, output_dim)\n",
    "            recon_all.append(recon_batch)\n",
    "    \n",
    "        recon_changing_y = torch.cat(recon_all)\n",
    "        recon_changing_y = torch.cat([x.view(-1, output_dim), recon_changing_y]).cpu()\n",
    "        return recon_changing_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/600 [00:00<?, ?it/s]/root/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "100%|██████████| 600/600 [00:03<00:00, 174.86it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 Train loss:0.5270\n",
      "Test loss:0.5084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:03<00:00, 187.66it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2 Train loss:0.5115\n",
      "Test loss:0.5093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:02<00:00, 211.48it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:3 Train loss:0.5113\n",
      "Test loss:0.5081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:03<00:00, 169.88it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:4 Train loss:0.5114\n",
      "Test loss:0.5080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:03<00:00, 169.82it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:5 Train loss:0.5112\n",
      "Test loss:0.5094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:02<00:00, 205.40it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:6 Train loss:0.5113\n",
      "Test loss:0.5082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:03<00:00, 208.84it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:7 Train loss:0.5112\n",
      "Test loss:0.5088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:03<00:00, 186.62it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:8 Train loss:0.5112\n",
      "Test loss:0.5078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:03<00:00, 181.49it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:9 Train loss:0.5110\n",
      "Test loss:0.5079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:03<00:00, 172.41it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10 Train loss:0.5111\n",
      "Test loss:0.5089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:03<00:00, 170.08it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:11 Train loss:0.5109\n",
      "Test loss:0.5080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:02<00:00, 206.71it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:12 Train loss:0.5109\n",
      "Test loss:0.5080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:03<00:00, 184.74it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:13 Train loss:0.5109\n",
      "Test loss:0.5089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:03<00:00, 169.71it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:14 Train loss:0.5111\n",
      "Test loss:0.5077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:03<00:00, 169.74it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:15 Train loss:0.5108\n",
      "Test loss:0.5078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:03<00:00, 171.54it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:16 Train loss:0.5109\n",
      "Test loss:0.5079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:03<00:00, 170.12it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:17 Train loss:0.5108\n",
      "Test loss:0.5086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:02<00:00, 206.75it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:18 Train loss:0.5108\n",
      "Test loss:0.5077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:02<00:00, 211.38it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:19 Train loss:0.5108\n",
      "Test loss:0.5083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:03<00:00, 171.61it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:20 Train loss:0.5108\n",
      "Test loss:0.5086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:03<00:00, 172.62it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:21 Train loss:0.5109\n",
      "Test loss:0.5076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:03<00:00, 169.34it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:22 Train loss:0.5107\n",
      "Test loss:0.5079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:03<00:00, 169.79it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:23 Train loss:0.5108\n",
      "Test loss:0.5086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:03<00:00, 186.81it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:24 Train loss:0.5108\n",
      "Test loss:0.5076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:03<00:00, 188.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:25 Train loss:0.5108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 17/600 [00:00<00:03, 168.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:0.5083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:03<00:00, 165.95it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:26 Train loss:0.5107\n",
      "Test loss:0.5080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:03<00:00, 169.71it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:27 Train loss:0.5107\n",
      "Test loss:0.5080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:03<00:00, 169.19it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:28 Train loss:0.5106\n",
      "Test loss:0.5082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:03<00:00, 169.61it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:29 Train loss:0.5106\n",
      "Test loss:0.5083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:03<00:00, 171.57it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:30 Train loss:0.5109\n",
      "Test loss:0.5079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:03<00:00, 170.35it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:31 Train loss:0.5106\n",
      "Test loss:0.5081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:03<00:00, 173.30it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:32 Train loss:0.5107\n",
      "Test loss:0.5079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:03<00:00, 170.42it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:33 Train loss:0.5107\n",
      "Test loss:0.5078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:03<00:00, 168.26it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:34 Train loss:0.5107\n",
      "Test loss:0.5079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:03<00:00, 174.97it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:35 Train loss:0.5107\n",
      "Test loss:0.5076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:03<00:00, 171.52it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:36 Train loss:0.5106\n",
      "Test loss:0.5077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:03<00:00, 169.84it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:37 Train loss:0.5106\n",
      "Test loss:0.5080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:03<00:00, 166.41it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:38 Train loss:0.5107\n",
      "Test loss:0.5077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:03<00:00, 170.32it/s]\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:39 Train loss:0.5107\n",
      "Test loss:0.5077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:03<00:00, 180.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:40 Train loss:0.5107\n",
      "Test loss:0.5082\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "plot_number = 1\n",
    "\n",
    "z_sample = 0.5 * torch.randn(64, latent_dim).to(device)\n",
    "y_sample = torch.eye(2)[[plot_number]*64].to(device)\n",
    "\n",
    "_y, _x = iter(x_test_loader).next()\n",
    "_x, _y = data_shaper(_x, _y, input_dim)\n",
    "_x = _x.to(device)\n",
    "_y = _y.to(device)\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss = train(epoch, input_dim)\n",
    "    test_loss = test(epoch, input_dim)\n",
    "    \n",
    "    recon = plot_reconstrunction(_x[:8], _c[:8], output_dim)\n",
    "    sample = plot_image_from_latent(z_sample, y_sample, output_dim)\n",
    "    recon_changing_y = plot_reconstraction_changing_y(_x[:8], _y[:8], output_dim)\n",
    "    \n",
    "\n",
    "    writer.add_scalar('train_loss', train_loss.item(), epoch)\n",
    "    writer.add_scalar('test_loss', test_loss.item(), epoch)      \n",
    "    \"\"\"\n",
    "    writer.add_image('Image_from_latent', sample, epoch)\n",
    "    writer.add_image('Image_reconstrunction', recon, epoch)\n",
    "    writer.add_image('Image_reconstrunction_change_y', recon_changing_y, epoch)\n",
    "    \"\"\"\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "pt_size = 10000\n",
    "z_sample = 0.5 * torch.randn(pt_size, latent_dim).to(device)\n",
    "\n",
    "# 非治療群を生成\n",
    "plot_number = 0\n",
    "y_sample = torch.eye(2)[[plot_number]*pt_size].to(device)\n",
    "untreated =  plot_image_from_latent(z_sample,y_sample , output_dim)\n",
    "# 治療群を生成\n",
    "plot_number = 1\n",
    "y_sample = torch.eye(2)[[plot_number]*pt_size].to(device)\n",
    "treated =  plot_image_from_latent(z_sample,y_sample , output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "model2 = Estimator(cond_dim, hidden_dim, latent_dim, estimate_dim)\n",
    "model2.to(device)\n",
    "optimizer = torch.optim.SGD(model2.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/600 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'ToTensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1013-fbd7810bbb24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"y\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'ToTensor'"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, num_epochs+1):\n",
    "    for data in tqdm(train_loader):\n",
    "        y = data[:,0]\n",
    "        x = data[:,1]\n",
    "        o = data[:,2]\n",
    "        x, y = data_shaper(x, y, input_dim)\n",
    "        o = o.view(-1, estimate_dim).float()\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        o = o.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        z = q.sample({\"x\":x, \"y\":y}, return_all=False)\n",
    "        output = e.sample({\"z\":z,\"y\":y},return_all=False)\n",
    "    \n",
    "        \n",
    "        loss = criterion(output,o)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "    \n",
    "    total = 0\n",
    "    total_loss = 0\n",
    "    for data in test_loader:\n",
    "        y = data[:,0]\n",
    "        x = data[:,1]\n",
    "        o = data[:,2]\n",
    "        x, y = data_shaper(x, y, input_dim)\n",
    "        o = o(-1, estimate_dim).float()\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        o = o.to(device)\n",
    "        \n",
    "        z = q.sample({\"x\":x, \"y\":y}, return_all=False)\n",
    "        e = model2(z,y)\n",
    "        \n",
    "        loss = criterion(e,o)\n",
    "        \n",
    "        total_loss += loss *len(data)\n",
    "        total += len(data)\n",
    "    test_loss = total_loss/total.cpu()\n",
    "    \n",
    "    print('Epochs:{}, train_Loss:{}, test_Loss:{:.2f}'.format(epoch,loss.item(), test_loss.item()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 3), dtype=float64)"
      ]
     },
     "execution_count": 1004,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=iter(test_loader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 1007,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1029,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 1029,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(z).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
